Metadata-Version: 2.1
Name: bask
Version: 0.7.1
Summary: A fully Bayesian implementation of sequential model-based optimization
Home-page: https://github.com/kiudee/bayes-skopt
Author: Karlson Pfannschmidt
Author-email: kiudee@mail.upb.de
License: Apache Software License 2.0
Keywords: bask
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Software Development
Requires-Python: >=3.7
Requires-Dist: Click (>=7.0)
Requires-Dist: scikit-optimize
Requires-Dist: numpy
Requires-Dist: scipy
Requires-Dist: scikit-learn (<0.23,>=0.18.2)
Requires-Dist: matplotlib
Requires-Dist: emcee (>=3.0)
Requires-Dist: tqdm




.. image:: https://github.com/kiudee/bayes-skopt/raw/master/docs/images/header.png
   :width: 800 px
   :alt: Bayes-skopt header
   :align: center

===========
Bayes-skopt
===========

.. image:: https://mybinder.org/badge_logo.svg
        :target: https://mybinder.org/v2/gh/kiudee/bayes-skopt/master?filepath=examples

.. image:: https://img.shields.io/pypi/v/bask.svg
        :target: https://pypi.python.org/pypi/bask

.. image:: https://img.shields.io/travis/kiudee/bayes-skopt.svg
        :target: https://travis-ci.org/kiudee/bayes-skopt

.. image:: https://readthedocs.org/projects/bayes-skopt/badge/?version=latest
        :target: https://bayes-skopt.readthedocs.io/en/latest/?badge=latest
        :alt: Documentation Status

.. image:: https://pyup.io/repos/github/kiudee/bayes-skopt/shield.svg
        :target: https://pyup.io/repos/github/kiudee/bayes-skopt/
        :alt: Updates

A fully Bayesian implementation of sequential model-based optimization


* Free software: Apache Software License 2.0
* Documentation: https://bayes-skopt.readthedocs.io.
* Built on top of the excellent `Scikit-Optimize (skopt) <https://github.com/scikit-optimize/scikit-optimize>`__.


Features
--------

- A **fully Bayesian** variant of the ``GaussianProcessRegressor``.
- State of the art information-theoretic acquisition functions, such as the
  `Max-value entropy search <https://arxiv.org/abs/1703.01968>`__ or
  `Predictive variance reduction search <https://bayesopt.github.io/papers/2017/13.pdf>`__, for even faster
  convergence in simple regret.
- Familiar `Optimizer` interface known from Scikit-Optimize.

Installation
------------

To install the latest stable release it is best to install the version on PyPI::

   pip install bask

The latest development version of Bayes-skopt can be installed from Github as follows::

   pip install git+https://github.com/kiudee/bayes-skopt

Another option is to clone the repository and install Bayes-skopt using::

   python setup.py install

Credits
-------

This package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.

.. _Cookiecutter: https://github.com/audreyr/cookiecutter
.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage


=======
History
=======

0.7.1 (2020-07-28)
------------------
* Restrict length scale bounds of the default kernel to a tighter interval.
  This should help start the MCMC walkers in a region with higher likelihood.

0.7.0 (2020-07-26)
------------------
* Replace the default inverse gamma distribution prior for the lengthscales by the round-flat distribution.
* Fix ``guess_priors`` to correctly add kernels with multiple lengthscales.

0.6.0 (2020-05-21)
------------------

* Add ``Optimizer.expected_optimality_gap`` which estimates the expected optimality gap of the current global optimum
  to random optima sampled from the Gaussian process.
* Check that the list of priors has the correct length.
* Require emcee to be at least version 3.0.

0.5.0 (2020-05-21)
------------------

* Add ``Optimizer.probability_of_optimality`` which estimates the probability that the current global optimum is
  optimal within a certain tolerance. This can be used to make stopping rules.

0.4.1 (2020-05-19)
------------------

* Update and fix dependencies.

0.4.0 (2020-04-27)
------------------

* Add ``return_policy`` parameter to ``BayesSearchCV``. Allows the user to choose between returning the best
  observed configuration (in a noise-less setting) or the best predicted configuration (for noisy targets).

0.3.3 (2020-03-16)
------------------

* Fix error occuring when an unknown argument was passed to ``Optimizer``.

0.3.0 (2020-03-12)
------------------

* Add predictive variance reduction search criterion. This is the new default
  acquisition function.
* Implement ``BayesSearchCV`` for use with scikit-learn estimators and
  pipelines. This is an easy to use drop-in replacement for GridSearchCV or
  RandomSearchCV. It is implemented as a wrapper around skopt.BayesSearchCV.
* Determine default kernels and priors to use, if the user provides none.
* Add example notebooks on how to use the library.
* Add API documentation of the library.


0.2.0 (2020-03-01)
------------------

* Allow user to pass a vector of noise variances to ``tell``, ``fit`` and ``sample``.
  This can be used to warm start the optimization process.

0.1.2 (2020-02-16)
------------------

* Fix the ``tell`` method of the optimizer not updating ``_n_initial_points`` correctly,
  when using replace.

0.1.0 (2020-02-01)
------------------

* First release on PyPI.


